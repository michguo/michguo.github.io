<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Michelle Guo</title>

    <meta name="author" content="Michelle Guo">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Michelle Guo
                </p>
                <p>
                  I am Michelle, a final-year PhD student in the Computer Science Department at Stanford University, where I am fortunate to be co-advised by <a href="https://jiajunwu.com/">Jiajun Wu</a> and <a href="https://tml.stanford.edu/people/karen-liu">C. Karen Liu</a>.
                </p>
                <p>
                  My research is graciously funded by the Meta Research Fellowship and the NSF Graduate Research Fellowship.
                  Previously, I received my BS and MS in Computer Science from Stanford University.
                </p>
                <p>
                  You can reach me at mguo95 [at] cs [dot] stanford [dot] edu!
                </p>
                <p style="text-align:center">
                  <a href="data/MichelleGuo-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=lyjjpNMAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/mshlguo">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/michguo/">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/shellguo95/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images/MichelleGuo.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images/MichelleGuo.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
                <p>My work lies in the intersection of computer vision, computer graphics, and robotics.</p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <!-- pgc -->
            <tr onmouseout="pgc_stop()" onmouseover="pgc_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='pgc_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/pgc.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/pgc.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function pgc_start() {
                    document.getElementById('pgc_image').style.opacity = "1";
                  }

                  function pgc_stop() {
                    document.getElementById('pgc_image').style.opacity = "0";
                  }
                  pgc_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://phys-gaussian-cloth.github.io/">
              <span class="papertitle">PGC: Physics-Based Gaussian Cloth from a Single Pose</span>
                </a>
                <br>
                <strong>Michelle Guo</strong>,
                Matt Jen-Yuan Chiang,
                Igor Santesteban,
                Nikolaos Sarafianos,
                Hsiao-yu Chen,
                Oshri Halimi,
                Aljaž Božič,
                Shunsuke Saito,
                Jiajun Wu,
                C. Karen Liu,
                Tuur Stuyck,
                Egor Larionov
                <br>
                <em>CVPR</em>, 2025 &nbsp <font color=#FF8080><strong>(Highlight)</strong></font>
                <br>
                <a href="https://phys-gaussian-cloth.github.io/">project page</a>
                /
                <a href="https://arxiv.org/abs/2503.20779">arXiv</a>
                <p></p>
                <p>
                Using a hybrid 3DGS + mesh representation allows reconstructing photorealistic, simulation-ready cloth from multi-view images of a static scene.
                </p>
              </td>
            </tr>

            <!-- craft -->
            <tr onmouseout="craft_stop()" onmouseover="craft_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='craft_image'><img src='images/craft_after.jpg' width=100%></div>
                  <img src='images/craft_before.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function craft_start() {
                    document.getElementById('craft_image').style.opacity = "1";
                  }

                  function craft_stop() {
                    document.getElementById('craft_image').style.opacity = "0";
                  }
                  craft_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://miatang13.github.io/Craft/">
              <span class="papertitle">CRAFT: Designing Creative and Functional 3D Objects</span>
                </a>
                <br>
                <strong>Michelle Guo*</strong>,
                Mia Tang*,
                Hannah Cha,
                Ruohan Zhang,
                C. Karen Liu,
                Jiajun Wu (* equal contribution)
                <br>
                <em>WACV</em>, 2025
                <br>
                <a href="https://miatang13.github.io/Craft/">project page</a>
                /
                <a href="https://arxiv.org/abs/2412.03889">arXiv</a>
                <p></p>
                <p>
                CRAFT generates 3D shapes via a mesh optimization procedure guided by semantic prompts and contact constraints.
                </p>
              </td>
            </tr>

            <!-- objectadapt -->
            <tr onmouseout="objectadapt_stop()" onmouseover="objectadapt_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='objectadapt_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/objectadapt.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/objectadapt.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function objectadapt_start() {
                    document.getElementById('objectadapt_image').style.opacity = "1";
                  }

                  function objectadapt_stop() {
                    document.getElementById('objectadapt_image').style.opacity = "0";
                  }
                  objectadapt_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://object-adaptation.github.io/">
              <span class="papertitle">Learning to Design 3D Printable Adaptations on Everyday Objects for Robot Manipulation</span>
                </a>
                <br>
                <strong>Michelle Guo</strong>,
                Ziang Liu,
                Stephen Tian,
                Zhaoming Xie,
                Jiajun Wu,
                C. Karen Liu
                <br>
                <em>ICRA</em>, 2024
                <br>
                <a href="https://object-adaptation.github.io/">project page</a>
                <p></p>
                <p>
                Jointly learning to design and control 3D-printable object adaptions, expanding the set of objects that robots can use.
                </p>
              </td>
            </tr>

            <!-- tooldesign -->
            <tr onmouseout="tooldesign_stop()" onmouseover="tooldesign_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='tooldesign_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/tooldesign.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/tooldesign.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function tooldesign_start() {
                    document.getElementById('tooldesign_image').style.opacity = "1";
                  }

                  function tooldesign_stop() {
                    document.getElementById('tooldesign_image').style.opacity = "0";
                  }
                  tooldesign_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://robotic-tool-design.github.io/">
              <span class="papertitle">Learning to Design and Use Tools for Robotic Manipulation</span>
                </a>
                <br>
                Ziang Liu*, Stephen Tian*, <strong>Michelle Guo</strong>, C. Karen Liu, Jiajun Wu (* equal contribution)
                <br>
                <em>CoRL</em>, 2023
                <br>
                <a href="https://robotic-tool-design.github.io/">project page</a>
                /
                <a href="https://arxiv.org/abs/2311.00754">arXiv</a>
                <p></p>
                <p>
                Learning designer and controller policies that allow to robots to rapidly design, prototype, and control tools for goal-conditioned tasks.
                </p>
              </td>
            </tr>

            <!-- osf -->
            <tr onmouseout="osf_stop()" onmouseover="osf_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='osf_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images/osf.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images/osf.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function osf_start() {
                    document.getElementById('osf_image').style.opacity = "1";
                  }

                  function osf_stop() {
                    document.getElementById('osf_image').style.opacity = "0";
                  }
                  osf_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://kovenyu.com/osf/">
              <span class="papertitle">Learning Object-Centric Neural Scattering Functions for Free-viewpoint Relighting and Scene Composition</span>
                </a>
                <br>
                Hong-Xing Yu*, <strong>Michelle Guo*</strong>, Alireza Fathi, Yen-Yu Chang, Eric Ryan Chan, Ruohan Gao, Thomas Funkhouser, Jiajun Wu (* equal contribution)
                <br>
                <em>TMLR</em>, 2023
                <br>
                <a href="https://kovenyu.com/osf/">project page</a>
                /
                <a href="https://arxiv.org/abs/2303.06138">arXiv</a>
                <p></p>
                <p>
                Making object-centric NeRFs relightable and scene-composable, for both opaque and translucent objects, by modeling neural scattering functions.
                </p>
              </td>
            </tr>

            <!-- dano -->
            <tr onmouseout="dano_stop()" onmouseover="dano_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dano_image'><img src='images/dano.gif' width=100%></div>
                  <img src='images/dano.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function dano_start() {
                    document.getElementById('dano_image').style.opacity = "1";
                  }

                  function dano_stop() {
                    document.getElementById('dano_image').style.opacity = "0";
                  }
                  dano_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2210.09420">
              <span class="papertitle">Differentiable Physics Simulation of Dynamics-Augmented Neural Objects</span>
                </a>
                <br>
                Simon Le Cleac'h, Hong-Xing Yu, <strong>Michelle Guo</strong>, Taylor A Howell, Ruohan Gao, Jiajun Wu, Zachary Manchester, Mac Schwager
                <br>
                <em>RA-L</em>, 2023
                <br>
                <a href="https://arxiv.org/abs/2210.09420">arXiv</a>
                /
                <a href="https://youtu.be/Md0PM-wv_Xg">video</a>
                /
                <a href="https://docs.google.com/presentation/d/14_dLVGmXb5Y0YpDZdI-HyH2D16YB7iIu72HHW8df6Qg/edit?usp=sharing">poster</a>
                /
                <a href="https://docs.google.com/presentation/d/1uYU-7K42tEq_cMbQsqF0D9LvJEB9iEd8K-QTd2HC9cY/edit?usp=sharing">slides</a>
                <p></p>
                <p>
                  Making object-centric NeRFs simulation-ready, using a differentiable contact model based on the density field.
                </p>
              </td>
            </tr>

            <!-- contact -->
            <tr onmouseout="contact_stop()" onmouseover="contact_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='contact_image'><img src='images/contact.gif' width=100%></div>
                  <img src='images/contact.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function contact_start() {
                    document.getElementById('contact_image').style.opacity = "1";
                  }

                  function contact_stop() {
                    document.getElementById('contact_image').style.opacity = "0";
                  }
                  contact_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://sites.google.com/view/rigid-contact/">
              <span class="papertitle">Benchmarking Rigid Body Contact Models</span>
                </a>
                <br>
                <strong>Michelle Guo</strong>, Yifeng Jiang, Andrew Everett Spielberg, Jiajun Wu, C. Karen Liu
                <br>
                <em>L4DC</em>, 2023
                <br>
                <a href="https://sites.google.com/view/rigid-contact/">project page</a>
                /
                <a href="https://proceedings.mlr.press/v211/guo23b.html">paper</a>
                <p></p>
                <p>
                  Analyzing the capabilities of analytical, learned, and hybrid simulators in reproducing real-world rigid body contact behavior.
                </p>
              </td>
            </tr>

            <!-- dexgrasp -->
            <tr onmouseout="dexgrasp_stop()" onmouseover="dexgrasp_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dexgrasp_image'><img src='images/dexgrasp.png' width=100%></div>
                  <img src='images/dexgrasp.png' width="160">
                </div>
                <script type="text/javascript">
                  function dexgrasp_start() {
                    document.getElementById('dexgrasp_image').style.opacity = "1";
                  }

                  function dexgrasp_stop() {
                    document.getElementById('dexgrasp_image').style.opacity = "0";
                  }
                  dexgrasp_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2207.00195">
              <span class="papertitle">Learning Diverse and Physically Feasible Dexterous Grasps with Generative Model and Bilevel Optimization</span>
                </a>
                <br>
                Albert Wu, <strong>Michelle Guo</strong>, C. Karen Liu
                <br>
                <em>CoRL</em>, 2022
                <br>
                <a href="https://arxiv.org/abs/2207.00195">arXiv</a>
                /
                <a href="https://proceedings.mlr.press/v205/wu23b.html">paper</a>
                /
                <a href="https://github.com/Stanford-TML/dex_grasp">code</a>
                /
                <a href="https://youtu.be/9DTrImbN99I?feature=shared">video</a>
                <p></p>
                <p>
                  Dexterous grasping of diverse objects via a generative model and bilevel optimization to plan diverse, physically feasible grasps in the real world.
                </p>
              </td>
            </tr>

            <!-- dash -->
            <tr onmouseout="dash_stop()" onmouseover="dash_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dash_image'><img src='images/dash.png' width=100%></div>
                  <img src='images/dash.png' width="160">
                </div>
                <script type="text/javascript">
                  function dash_start() {
                    document.getElementById('dash_image').style.opacity = "1";
                  }

                  function dash_stop() {
                    document.getElementById('dash_image').style.opacity = "0";
                  }
                  dash_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2108.12536">
              <span class="papertitle">DASH: Modularized Human Manipulation Simulation with Vision and Language for Embodied AI</span>
                </a>
                <br>
                Yifeng Jiang, <strong>Michelle Guo</strong>, Jiangshan Li, Ioannis Exarchos, Jiajun Wu, C. Karen Liu
                <br>
                <em>SCA</em>, 2021
                <br>
                <a href="https://arxiv.org/abs/2108.12536">arXiv</a>
                /
                <a href="https://youtu.be/8Th95GdtQ3M">video</a>
                /
                <a href="https://drive.google.com/file/d/1t7sU5jCn_zY-TAJu2u1E_p7ZxEFUoXJJ/view?usp=sharing">talk slides</a>
                /
                <a href="https://github.com/jyf588/pytorch-rl-bullet">code</a>
                <p></p>
                <p>
                  An embodied virtual human that, given natural language commands, performs grasp-and-stack tasks using its own perception, proprioception, and touch, without requiring human motion data.
                </p>
              </td>
            </tr>

            <!-- nature19 -->
            <tr onmouseout="nature19_stop()" onmouseover="nature19_start()">
              <td style="padding:16px;width:20%;">
                <div style="display: flex; align-items: center; height: 100%;">
                  <img src='images/nature19.jpg' width="160">
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://www.nature.com/articles/s41746-019-0087-z">
              <span class="papertitle">A Computer Vision System for Deep Learning-Based Detection of Patient Mobilization Activities in the ICU</span>
                </a>
                <br>
                Serena Yeung*, Francesca Rinaldo*, Jeffrey Jopling, Bingbin Liu, Rishab Mehra, N. Lance Downing, <strong>Michelle Guo</strong>, Gabriel M. Bianconi, Alexandre Alahi, Julia Lee, Brandi Campbell, Kayla Deru, William Beninati, Li Fei-Fei, Arnold Milstein
                <br>
                Nature (npj) Digital Medicine, 2019
                <br>
                <a href="https://www.nature.com/articles/s41746-019-0087-z">paper</a>
              </td>
            </tr>

            <!-- icassp19 -->
            <tr onmouseout="icassp19_stop()" onmouseover="icassp19_start()">
              <td style="padding:16px;width:20%;">
                <div style="display: flex; align-items: center; height: 100%;">
                  <img src='images/icassp19.jpg' width="160">
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1902.07817">
              <span class="papertitle">Audio-Linguistic Embeddings for Spoken Sentences</span>
                </a>
                <br>
                Albert Haque, <strong>Michelle Guo</strong>, Prateek Verma, Li Fei-Fei
                <br>
                ICASSP, 2019
                <br>
                <a href="https://arxiv.org/abs/1902.07817">arXiv</a>
              </td>
            </tr>

            <!-- eccv18a -->
            <tr onmouseout="eccv18a_stop()" onmouseover="eccv18a_start()">
              <td style="padding:16px;width:20%;">
                <div style="display: flex; align-items: center; height: 100%;">
                  <img src='images/eccv18a.jpg' width="160">
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Michelle_Guo_Neural_Graph_Matching_ECCV_2018_paper.pdf">
              <span class="papertitle">Neural Graph Matching Networks for Fewshot 3D Action Recognition</span>
                </a>
                <br>
                <strong>Michelle Guo</strong>, Edward Chou, De-An Huang, Shuran Song, Serena Yeung, Li Fei-Fei
                <br>
                ECCV, 2018
                <br>
                <a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Michelle_Guo_Neural_Graph_Matching_ECCV_2018_paper.pdf">paper</a>
              </td>
            </tr>

            <!-- eccv18b -->
            <tr onmouseout="eccv18b_stop()" onmouseover="eccv18b_start()">
              <td style="padding:16px;width:20%;">
                <div style="display: flex; align-items: center; height: 100%;">
                  <img src='images/eccv18b.jpg' width="160">
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Michelle_Guo_Focus_on_the_ECCV_2018_paper.pdf">
              <span class="papertitle">Focus on the Hard Things: Dynamic Task Prioritization for Multitask Learning</span>
                </a>
                <br>
                <strong>Michelle Guo</strong>, Albert Haque, De-An Huang, Serena Yeung, Li Fei-Fei
                <br>
                ECCV, 2018
                <br>
                <a href="https://openaccess.thecvf.com/content_ECCV_2018/papers/Michelle_Guo_Focus_on_the_ECCV_2018_paper.pdf">paper</a>
              </td>
            </tr>

            <!-- interspeech18 -->
            <tr onmouseout="interspeech18_stop()" onmouseover="interspeech18_start()">
              <td style="padding:16px;width:20%;">
                <div style="display: flex; align-items: center; height: 100%;">
                  <img src='images/interspeech18.jpg' width="160">
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1804.00047">
              <span class="papertitle">Conditional End-to-End Audio Transforms</span>
                </a>
                <br>
                Albert Haque, <strong>Michelle Guo</strong>, Prateek Verma
                <br>
                Interspeech, 2018
                <br>
                <a href="https://arxiv.org/abs/1804.00047">arXiv</a>
              </td>
            </tr>

            <!-- ml4h18a -->
            <tr onmouseout="ml4h18a_stop()" onmouseover="ml4h18a_start()">
              <td style="padding:16px;width:20%;">
                <div style="display: flex; align-items: center; height: 100%;">
                  <img src='images/ml4h18a.jpg' width="160">
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1811.08592">
              <span class="papertitle">Measuring the Severity of Depressive Symptoms from Spoken Language and 3D Facial Expressions</span>
                </a>
                <br>
                Albert Haque, <strong>Michelle Guo</strong>, Adam S Miner, L Fei-Fei
                <br>
                NeurIPS Workshop on Machine Learning for Health (ML4H), 2018
                <br>
                <a href="https://arxiv.org/abs/1811.08592">arXiv</a>
              </td>
            </tr>

            <!-- ml4h18b -->
            <tr onmouseout="ml4h18b_stop()" onmouseover="ml4h18b_start()">
              <td style="padding:16px;width:20%;">
                <div style="display: flex; align-items: center; height: 100%;">
                  <img src='images/ml4h18b.jpg' width="160">
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1811.09950">
              <span class="papertitle">Privacy-Preserving Action Recognition for Smart Hospitals using Low-Resolution Depth Images</span>
                </a>
                <br>
                Edward Chou, Matthew Tan, Cherry Zou, <strong>Michelle Guo</strong>, Albert Haque, Arnold Milstein, Li Fei-Fei
                <br>
                NeurIPS Workshop on Machine Learning for Health (ML4H), 2018
                <br>
                <a href="https://arxiv.org/abs/1811.09950">arXiv</a>
              </td>
            </tr>

            <!-- mlhc18 -->
            <tr onmouseout="mlhc18_stop()" onmouseover="mlhc18_start()">
              <td style="padding:16px;width:20%;">
                <div style="display: flex; align-items: center; height: 100%;">
                  <img src='images/mlhc18.jpg' width="160">
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://proceedings.mlr.press/v85/liu18a/liu18a.pdf">
              <span class="papertitle">3D Point Cloud-Based Visual Prediction of ICU Mobility Care Activities</span>
                </a>
                <br>
                Bingbin Liu*, <strong>Michelle Guo*</strong>, Edward Chou, Rishab Mehra, Serena Yeung, N. Lance Downing, Francesca Salipur, Jeffrey Jopling, Brandi Campbell, Kayla Deru, William Beninati, Arnold Milstein (* equal contribution)
                <br>
                Machine Learning for Health Care (MLHC), 2018
                <br>
                <a href="https://proceedings.mlr.press/v85/liu18a/liu18a.pdf">paper</a>
              </td>
            </tr>

            <!-- ml4h17 -->
            <tr onmouseout="ml4h17_stop()" onmouseover="ml4h17_start()">
              <td style="padding:16px;width:20%;">
                <div style="display: flex; align-items: center; height: 100%;">
                  <img src='images/ml4h17.jpg' width="160">
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="./data/ml4h17.pdf">
              <span class="papertitle">Viewpoint Invariant Convolutional Networks for Identifying Risky Hand Hygiene Scenarios</span>
                </a>
                <br>
                <strong>Michelle Guo</strong>, Albert Haque, Serena Yeung, Jeffrey Jopling, Lance Downing, Alexandre Alahi, Brandi Campbell, Kayla Deru, William Beninati, Arnold Milstein, Li Fei-Fei
                <br>
                NeurIPS Workshop on Machine Learning for Health (ML4H), 2017
                <br>
                <a href="./data/ml4h17.pdf">paper</a>
              </td>
            </tr>
            
            <!-- mlhc17 -->
            <tr onmouseout="mlhc17_stop()" onmouseover="mlhc17_start()">
              <td style="padding:16px;width:20%;">
                <div style="display: flex; align-items: center; height: 100%;">
                  <img src='images/mlhc17.jpg' width="160">
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1708.00163">
              <span class="papertitle">Towards Vision-Based Smart Hospitals: A System for Tracking and Monitoring Hand Hygiene Compliance</span>
                </a>
                <br>
                Albert Haque, <strong>Michelle Guo</strong>, Alexandre Alahi, Serena Yeung, Zelun Luo, Alisha Rege, Jeffrey Jopling, Lance Downing, William Beninati, Amit Singh, Terry Platchek, Arnold Milstein, Li Fei-Fei
                <br>
                Machine Learning for Healthcare Conference (MLHC), 2017
                <br>
                <a href="https://arxiv.org/abs/1708.00163">arXiv</a>
              </td>
            </tr>

            <!-- icassp17 -->
            <tr onmouseout="icassp17_stop()" onmouseover="icassp17_start()">
              <td style="padding:16px;width:20%;">
                <div style="display: flex; align-items: center; height: 100%;">
                  <img src='images/icassp17.jpg' width="160">
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1608.00892">
              <span class="papertitle">Knowledge Distillation for Small-footprint Highway Networks</span>
                </a>
                <br>
                Liang Lu, Michelle Guo, Steve Renals
                <br>
                ICASSP, 2017
                <br>
                <a href="https://arxiv.org/abs/1608.00892">arXiv</a>
              </td>
            </tr>

            <!-- apj16 -->
            <tr onmouseout="apj16_stop()" onmouseover="apj16_start()">
              <td style="padding:16px;width:20%;">
                <div style="display: flex; align-items: center; height: 100%;">
                  <img src='images/apj16.jpg' width="160">
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1601.01315">
              <span class="papertitle">Lithium-Rich Giants in Globular Clusters</span>
                </a>
                <br>
                Evan N Kirby, Puragra Guhathakurta, Andrew J Zhang, Jerry Hong, Michelle Guo, Rachel Guo, Judith G Cohen, Katia Cunha
                <br>
                The Astrophysical Journal (ApJ), 2016
                <br>
                <a href="https://arxiv.org/abs/1601.01315">arXiv</a>
              </td>
            </tr>

            <!-- apj15 -->
            <tr onmouseout="apj15_stop()" onmouseover="apj15_start()">
              <td style="padding:16px;width:20%;">
                <div style="display: flex; align-items: center; height: 100%;">
                  <img src='images/apj15.jpg' width="160">
                </div>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/1501.06908">
              <span class="papertitle">Carbon in Red Giants in Globular Clusters and Dwarf Spheroidal Galaxies</span>
                </a>
                <br>
                Evan N Kirby, Michelle Guo, Andrew J Zhang, Michelle Deng, Judith G Cohen, Puragra Guhathakurta, Matthew D Shetrone, Young Sun Lee, Luca Rizzi
                <br>
                The Astrophysical Journal (ApJ), 2015
                <br>
                <a href="https://arxiv.org/abs/1501.06908">arXiv</a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Website template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
