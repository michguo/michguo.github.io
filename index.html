<!DOCTYPE HTML>
<html lang="en">
  <head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">

    <title>Michelle Guo</title>

    <meta name="author" content="Michelle Guo">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="shortcut icon" href="images-mg/favicon/favicon.ico" type="image/x-icon">
    <link rel="stylesheet" type="text/css" href="stylesheet.css">
    
  </head>

  <body>
    <table style="width:100%;max-width:800px;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
      <tr style="padding:0px">
        <td style="padding:0px">
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr style="padding:0px">
              <td style="padding:2.5%;width:63%;vertical-align:middle">
                <p class="name" style="text-align: center;">
                  Michelle Guo
                </p>
                <p>
                  I am Michelle, a final-year PhD student in the Computer Science Department at Stanford University, where I am fortunate to be co-advised by <a href="https://jiajunwu.com/">Jiajun Wu</a> and <a href="https://tml.stanford.edu/people/karen-liu">C. Karen Liu</a>.
                </p>
                <p>
                  My research is graciously funded by the Meta Research Fellowship and the NSF Graduate Research Fellowship.
                  Previously, I received my BS and MS in Computer Science from Stanford University.
                </p>
                <p>
                  You can reach me at mguo95 [at] cs [dot] stanford [dot] edu!
                </p>
                <p style="text-align:center">
                  <a href="data-mg/MichelleGuo-CV.pdf">CV</a> &nbsp;/&nbsp;
                  <a href="https://scholar.google.com/citations?user=lyjjpNMAAAAJ&hl=en">Google Scholar</a> &nbsp;/&nbsp;
                  <a href="https://twitter.com/mshlguo">Twitter</a> &nbsp;/&nbsp;
                  <a href="https://github.com/michguo/">Github</a> &nbsp;/&nbsp;
                  <a href="https://www.linkedin.com/in/shellguo95/">LinkedIn</a>
                </p>
              </td>
              <td style="padding:2.5%;width:37%;max-width:37%">
                <a href="images-mg/MichelleGuo.jpg"><img style="width:100%;max-width:100%;object-fit: cover; border-radius: 50%;" alt="profile photo" src="images-mg/MichelleGuo.jpg" class="hoverZoomLink"></a>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
              <tr>
              <td style="padding:16px;width:100%;vertical-align:middle">
                <h2>Research</h2>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px 10px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <!-- pgc -->
            <tr onmouseout="pgc_stop()" onmouseover="pgc_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='pgc_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images-mg/pgc.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images-mg/pgc.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function pgc_start() {
                    document.getElementById('pgc_image').style.opacity = "1";
                  }

                  function pgc_stop() {
                    document.getElementById('pgc_image').style.opacity = "0";
                  }
                  pgc_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://phys-gaussian-cloth.github.io/">
              <span class="papertitle">PGC: Physics-Based Gaussian Cloth from a Single Pose</span>
                </a>
                <br>
                <strong>Michelle Guo</strong>,
                Matt Jen-Yuan Chiang,
                Igor Santesteban,
                Nikolaos Sarafianos,
                Hsiao-yu Chen,
                Oshri Halimi,
                Aljaž Božič,
                Shunsuke Saito,
                Jiajun Wu,
                C. Karen Liu,
                Tuur Stuyck,
                Egor Larionov
                <br>
                <em>CVPR</em>, 2025 &nbsp <font color=#FF8080><strong>(Highlight)</strong></font>
                <br>
                <a href="https://phys-gaussian-cloth.github.io/">project page</a>
                /
                <a href="https://arxiv.org/abs/2503.20779">arXiv</a>
                <p></p>
                <p>
                Using a hybrid 3DGS + mesh representation allows reconstructing photorealistic, simulation-ready cloth from multi-view images of a static scene.
                </p>
              </td>
            </tr>

            <!-- craft -->
            <tr onmouseout="craft_stop()" onmouseover="craft_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='craft_image'><img src='images-mg/craft_after.jpg' width=100%></div>
                  <img src='images-mg/craft_before.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function craft_start() {
                    document.getElementById('craft_image').style.opacity = "1";
                  }

                  function craft_stop() {
                    document.getElementById('craft_image').style.opacity = "0";
                  }
                  craft_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://miatang13.github.io/Craft/">
              <span class="papertitle">CRAFT: Designing Creative and Functional 3D Objects</span>
                </a>
                <br>
                <strong>Michelle Guo*</strong>,
                Mia Tang*,
                Hannah Cha,
                Ruohan Zhang,
                C. Karen Liu,
                Jiajun Wu (* equal contribution)
                <br>
                <em>WACV</em>, 2025
                <br>
                <a href="https://miatang13.github.io/Craft/">project page</a>
                /
                <a href="https://arxiv.org/abs/2412.03889">arXiv</a>
                <p></p>
                <p>
                CRAFT generates 3D shapes via a mesh optimization procedure guided by semantic prompts and contact constraints.
                </p>
              </td>
            </tr>

            <!-- objectadapt -->
            <tr onmouseout="objectadapt_stop()" onmouseover="objectadapt_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='objectadapt_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images-mg/objectadapt.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images-mg/objectadapt.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function objectadapt_start() {
                    document.getElementById('objectadapt_image').style.opacity = "1";
                  }

                  function objectadapt_stop() {
                    document.getElementById('objectadapt_image').style.opacity = "0";
                  }
                  objectadapt_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://object-adaptation.github.io/">
              <span class="papertitle">Learning to Design 3D Printable Adaptations on Everyday Objects for Robot Manipulation</span>
                </a>
                <br>
                <strong>Michelle Guo</strong>,
                Ziang Liu,
                Stephen Tian,
                Zhaoming Xie,
                Jiajun Wu,
                C. Karen Liu
                <br>
                <em>ICRA</em>, 2024
                <br>
                <a href="https://object-adaptation.github.io/">project page</a>
                <p></p>
                <p>
                Jointly learning to design and control 3D-printable object adaptions, expanding the set of objects that robots can use.
                </p>
              </td>
            </tr>

            <!-- tooldesign -->
            <tr onmouseout="tooldesign_stop()" onmouseover="tooldesign_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='tooldesign_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images-mg/tooldesign.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images-mg/tooldesign.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function tooldesign_start() {
                    document.getElementById('tooldesign_image').style.opacity = "1";
                  }

                  function tooldesign_stop() {
                    document.getElementById('tooldesign_image').style.opacity = "0";
                  }
                  tooldesign_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://robotic-tool-design.github.io/">
              <span class="papertitle">Learning to Design and Use Tools for Robotic Manipulation</span>
                </a>
                <br>
                Ziang Liu*, Stephen Tian*, <strong>Michelle Guo</strong>, C. Karen Liu, Jiajun Wu (* equal contribution)
                <br>
                <em>CoRL</em>, 2023
                <br>
                <a href="https://robotic-tool-design.github.io/">project page</a>
                /
                <a href="https://arxiv.org/abs/2311.00754">arXiv</a>
                <p></p>
                <p>
                Learning designer and controller policies that allow to robots to rapidly design, prototype, and control tools for goal-conditioned tasks.
                </p>
              </td>
            </tr>

            <!-- osf -->
            <tr onmouseout="osf_stop()" onmouseover="osf_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='osf_image'><video  width=100% height=100% muted autoplay loop>
                  <source src="images-mg/osf.mp4" type="video/mp4">
                  Your browser does not support the video tag.
                  </video></div>
                  <img src='images-mg/osf.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function osf_start() {
                    document.getElementById('osf_image').style.opacity = "1";
                  }

                  function osf_stop() {
                    document.getElementById('osf_image').style.opacity = "0";
                  }
                  osf_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://kovenyu.com/osf/">
              <span class="papertitle">Learning Object-Centric Neural Scattering Functions for Free-viewpoint Relighting and Scene Composition</span>
                </a>
                <br>
                Hong-Xing Yu*, <strong>Michelle Guo*</strong>, Alireza Fathi, Yen-Yu Chang, Eric Ryan Chan, Ruohan Gao, Thomas Funkhouser, Jiajun Wu (* equal contribution)
                <br>
                <em>TMLR</em>, 2023
                <br>
                <a href="https://kovenyu.com/osf/">project page</a>
                /
                <a href="https://arxiv.org/abs/2303.06138">arXiv</a>
                <p></p>
                <p>
                Making object-centric NeRFs relightable and scene-composable, for both opaque and translucent objects, by modeling neural scattering functions.
                </p>
              </td>
            </tr>

            <!-- dano -->
            <tr onmouseout="dano_stop()" onmouseover="dano_start()">
              <td style="padding:16px;width:20%;vertical-align:middle">
                <div class="one">
                  <div class="two" id='dano_image'><img src='images-mg/dano.gif' width=100%></div>
                  <img src='images-mg/dano.jpg' width="160">
                </div>
                <script type="text/javascript">
                  function dano_start() {
                    document.getElementById('dano_image').style.opacity = "1";
                  }

                  function dano_stop() {
                    document.getElementById('dano_image').style.opacity = "0";
                  }
                  dano_stop()
                </script>
              </td>
              <td style="padding:8px;width:80%;vertical-align:middle">
                <a href="https://arxiv.org/abs/2210.09420">
              <span class="papertitle">Differentiable Physics Simulation of Dynamics-Augmented Neural Objects</span>
                </a>
                <br>
                Simon Le Cleac'h, Hong-Xing Yu, <strong>Michelle Guo</strong>, Taylor A Howell, Ruohan Gao, Jiajun Wu, Zachary Manchester, Mac Schwager
                <br>
                <em>RA-L</em>, 2023
                <br>
                <a href="https://arxiv.org/abs/2210.09420">arXiv</a>
                /
                <a href="https://youtu.be/Md0PM-wv_Xg">video</a>
                /
                <a href="https://docs.google.com/presentation/d/14_dLVGmXb5Y0YpDZdI-HyH2D16YB7iIu72HHW8df6Qg/edit?usp=sharing">poster</a>
                /
                <a href="https://docs.google.com/presentation/d/1uYU-7K42tEq_cMbQsqF0D9LvJEB9iEd8K-QTd2HC9cY/edit?usp=sharing">slides</a>
                <p></p>
                <p>
                  Making object-centric NeRFs simulation-ready, using a differentiable contact model based on the density field.
                </p>
              </td>
            </tr>
          </tbody></table>
          <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
            <tr>
              <td style="padding:0px">
                <br>
                <p style="text-align:center;font-size:small;">
                  Website template from <a href="https://github.com/jonbarron/jonbarron_website">Jon Barron</a>.
                </p>
              </td>
            </tr>
          </tbody></table>
        </td>
      </tr>
    </table>
  </body>
</html>
